# Speech Recognize Audio Captioning ğŸ†™ï¸

## 1ï¸âƒ£ Project Description

* Dá»± Ã¡n demo há»‡ thá»‘ng nháº­n dáº¡ng audio vÃ  sinh mÃ´ táº£ báº±ng AI.
* Backend: FastAPI
* Frontend: Streamlit
* Model inference: AudioCaptioningModel

---

## 2ï¸âƒ£ Folder Struture

```bash
.
â”œâ”€â”€ backend/        # FastAPI backend
â”œâ”€â”€ frontend/       # Streamlit frontend
â”œâ”€â”€ inference/      # Model & tokenizer loading
â”œâ”€â”€ model_weights/  # File model, tokenizer
â”œâ”€â”€ training/       # (Optional: Training code)
â”œâ”€â”€ data/           # (Optional: Dataset)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
```

---

## 3ï¸âƒ£ Deploy LOCAL (recommended to run local first)

### BÆ°á»›c 1: Create virtual environment

```bash
python -m venv .venv
```

### BÆ°á»›c 2: Activate virtual environment

Windows:

```bash
.\.venv\Scripts\activate
```

Linux/Mac:

```bash
source .venv/bin/activate
```

### BÆ°á»›c 3: Set up dependencies

Backend:

```bash
cd backend
pip install -r requirements.txt
```

Frontend:

```bash
cd ../frontend
pip install -r requirements.txt
```

### BÆ°á»›c 4: Run backend

Back to root directory project:

```bash
cd ../
uvicorn backend.main:app --reload
```

Backend will run at: `http://127.0.0.1:8000`

### BÆ°á»›c 5: Run frontend

Open new terminal:

```bash
cd frontend
streamlit run app.py
```

Frontend will run at: `http://localhost:8501`

---

## 4ï¸âƒ£ Run with Docker (optional)

### BÆ°á»›c 1: Prepare Docker Compose

```bash
docker-compose up --build
```

After build is complete, access:

* Backend: `http://localhost:8000`
* Frontend: `http://localhost:8501`

### LÆ°u Ã½:

* In Docker Compose, backend + frontend are installed with automatic environment.
* Docker cache locally is usually large because it includes images, layers, etc.

---

## 5ï¸âƒ£ Ghi chÃº quan trá»ng

* Model files (.pth), tokenizer.pkl must be placed in the correct location `model_weights/`.
* Files in `inference/` are used for loading models when the backend starts.
* In Docker build, the more dependencies, the first build will be slower (due to caching), the next will be faster.

---


