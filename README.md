# Real-time Speech Transcription and Summarization System

An end-to-end system that supports **real-time audio captioning**, **speech recognition**, and **summarization**, designed for intelligent audio understanding applications. Powered by state-of-the-art deep learning models (ResNet, LSTM, Whisper, Wav2Vec2, PEGASUS, T5), deployed with FastAPI + Streamlit + Docker.

---

## üéØ Use Cases
- üñºÔ∏è **Audio Captioning**: Generate natural-language descriptions of arbitrary sounds (e.g., "a dog barking", "applause", "car engine revving").
- üó£Ô∏è **Speech Transcription**: Convert human speech to text using ASR models (Whisper, Wav2Vec2).
- ‚úÇÔ∏è **Summarization**: Summarize long-form spoken content into concise text with T5 / PEGASUS.

---

## üõ†Ô∏è Technologies
- Python, FastAPI, Streamlit
- PyTorch, TorchAudio, Transformers (HuggingFace)
- ASR: Whisper, Wav2Vec2
- Summarizer: PEGASUS, T5
- Audio Captioning: ResNet + LSTM
- Docker, Docker Compose

---

## üîß Quick Setup
### 1Ô∏è‚É£ Clone repo & setup env
```bash
git clone https://github.com/BinhTa2004/Speech-Transcription.git
cd Speech-Transcription

python -m venv .venv
source .venv/bin/activate  # Windows: .\.venv\Scripts\activate
```

### 2Ô∏è‚É£ Install dependencies
```bash
pip install -r requirements.txt
```
### 3Ô∏è‚É£ Run backend (FastAPI)
```bash
uvicorn backend.main:app --reload
```
### 4Ô∏è‚É£ Run frontend (Streamlit)
```bash
cd frontend
streamlit run app.py
```
### üê≥ Docker (optional)
```bash
docker-compose up --build
```
‚ö†Ô∏è Notes:
* The first build may take several minutes as Docker installs models and dependencies.
* Docker images and layers can consume significant disk space (especially with deep learning models).
